"""
AutoML Platform - Wizard Page
==============================

Page de l'assistant de cr√©ation de projet AutoML.
Cette page guide l'utilisateur √† travers les √©tapes de configuration d'un mod√®le.
"""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from sqlalchemy import create_engine
from datetime import datetime
from io import BytesIO
from urllib.parse import urlparse, parse_qs, urlencode, urlunparse
import re
import time
import math
from typing import Optional, Dict, List, Any, Tuple
import numpy as np
import requests

# Configuration de la page
st.set_page_config(
    page_title="Assistant AutoML",
    page_icon="üéØ",
    layout="wide",
    initial_sidebar_state="expanded"
)


class SessionState:
    """Gestionnaire d'√©tat de session pour l'assistant."""
    
    @staticmethod
    def initialize():
        """Initialise l'√©tat de la session si n√©cessaire."""
        defaults = {
            'wizard_step': 0,
            'uploaded_data': None,
            'selected_target': None,
            'selected_template': None,
            'training_config': {},
            'expert_mode': False,
            'training_status': 'idle',
            'manual_prediction_df': None,
            'manual_prediction_columns': [],
            'manual_prediction_results': None,
            'manual_prediction_schema': {},
            'manual_prediction_validation_errors': {},
            'selected_task_type': None,
            'target_classes': [],
            'target_stats': {}
        }
        
        for key, value in defaults.items():
            if key not in st.session_state:
                st.session_state[key] = value


class DataLoader:
    """Gestionnaire de chargement de donn√©es."""
    
    @staticmethod
    def load_from_file(uploaded_file) -> Optional[pd.DataFrame]:
        """Charge les donn√©es depuis un fichier upload√©."""
        if uploaded_file is None:
            return None
        
        try:
            file_extension = uploaded_file.name.split('.')[-1].lower()
            
            if file_extension == 'csv':
                df = pd.read_csv(uploaded_file)
            elif file_extension in ['xlsx', 'xls']:
                df = pd.read_excel(uploaded_file)
            elif file_extension == 'parquet':
                df = pd.read_parquet(uploaded_file)
            elif file_extension == 'json':
                df = pd.read_json(uploaded_file)
            else:
                st.error(f"Format de fichier non support√©: {file_extension}")
                return None
            
            return df
            
        except Exception as e:
            st.error(f"Erreur lors du chargement du fichier: {str(e)}")
            return None


class AutoMLWizard:
    """Assistant de configuration AutoML guid√©."""
    
    def __init__(self):
        self.steps = [
            "üì§ Chargement des donn√©es",
            "üéØ S√©lection de l'objectif", 
            "‚öôÔ∏è Configuration du mod√®le",
            "üöÄ Entra√Ænement",
            "üìä R√©sultats"
        ]
    
    def render(self):
        """Affiche l'assistant √©tape par √©tape."""
        # Titre de la page
        st.title("üéØ Assistant AutoML")
        st.markdown("---")
        
        # Barre de progression
        if len(self.steps) > 1:
            progress = st.session_state.wizard_step / (len(self.steps) - 1)
        else:
            progress = 0
        st.progress(progress)
        
        # Affichage des √©tapes
        cols = st.columns(len(self.steps))
        for idx, (col, step) in enumerate(zip(cols, self.steps)):
            with col:
                if idx < st.session_state.wizard_step:
                    st.success(step, icon="‚úÖ")
                elif idx == st.session_state.wizard_step:
                    st.info(step, icon="üëâ")
                else:
                    st.text(step)
        
        st.divider()
        
        # Contenu de l'√©tape actuelle
        if st.session_state.wizard_step == 0:
            self._step_data_loading()
        elif st.session_state.wizard_step == 1:
            self._step_target_selection()
        elif st.session_state.wizard_step == 2:
            self._step_model_configuration()
        elif st.session_state.wizard_step == 3:
            self._step_training()
        elif st.session_state.wizard_step == 4:
            self._step_results()

    def _reset_manual_prediction_state(self) -> None:
        """R√©initialise l'√©tat li√© aux pr√©dictions manuelles."""
        st.session_state.manual_prediction_df = None
        st.session_state.manual_prediction_columns = []
        st.session_state.manual_prediction_results = None
        st.session_state.manual_prediction_schema = {}
        st.session_state.manual_prediction_validation_errors = {}

    def _display_loaded_data(self, df: pd.DataFrame, source_label: str) -> None:
        """Enregistre les donn√©es charg√©es et affiche un r√©sum√© standardis√©."""
        st.session_state.uploaded_data = df
        st.session_state.selected_target = None
        st.session_state.selected_task_type = None
        st.session_state.target_classes = []
        st.session_state.target_stats = {}
        self._reset_manual_prediction_state()
        st.success(f"‚úÖ {len(df)} lignes et {len(df.columns)} colonnes charg√©es depuis {source_label}")

        with st.expander("Aper√ßu des donn√©es", expanded=True):
            st.dataframe(df.head(10))

        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Lignes", f"{len(df):,}")
        with col2:
            st.metric("Colonnes", len(df.columns))
        with col3:
            st.metric("Valeurs manquantes", f"{df.isna().sum().sum():,}")

    @staticmethod
    def _default_value_for_dtype(dtype: Any):
        """Retourne une valeur par d√©faut selon le type de donn√©e."""
        if dtype is not None and pd.api.types.is_bool_dtype(dtype):
            return False
        return None

    @staticmethod
    def _build_column_configs(schema: Dict[str, Any]) -> Dict[str, Any]:
        """Construit les configurations de colonnes pour le data editor."""
        configs: Dict[str, Any] = {}
        for column, dtype in schema.items():
            if pd.api.types.is_datetime64_any_dtype(dtype):
                configs[column] = st.column_config.DatetimeColumn(column)
            elif pd.api.types.is_numeric_dtype(dtype):
                configs[column] = st.column_config.NumberColumn(column)
            elif pd.api.types.is_bool_dtype(dtype):
                configs[column] = st.column_config.CheckboxColumn(column)
            else:
                configs[column] = st.column_config.TextColumn(column)
        return configs

    @staticmethod
    def _is_non_empty_value(value: Any) -> bool:
        """D√©termine si une valeur doit √™tre consid√©r√©e comme renseign√©e."""
        if value is None:
            return False
        if isinstance(value, str):
            return value.strip() != ""
        if isinstance(value, float) and np.isnan(value):
            return False
        if pd.isna(value):
            return False
        return True

    @staticmethod
    def _google_sheets_csv_url(url: str, worksheet: Optional[str]) -> str:
        """Normalise une URL Google Sheets pour r√©cup√©rer un CSV."""
        if not url or not url.strip():
            raise ValueError("Le lien Google Sheets est vide.")

        stripped_url = url.strip()
        normalized_sheet = worksheet.strip() if worksheet and worksheet.strip() else None
        normalized_input = stripped_url if "://" in stripped_url else f"https://{stripped_url}"
        parsed = urlparse(normalized_input)

        if not parsed.scheme:
            parsed = parsed._replace(scheme="https")

        if not parsed.netloc:
            raise ValueError("Le lien doit inclure un domaine valide (ex: docs.google.com).")

        normalized_netloc = parsed.netloc.lower()
        host = normalized_netloc.split(":", 1)[0]
        allowed_hosts = {"docs.google.com", "spreadsheets.google.com"}
        if host not in allowed_hosts:
            raise ValueError(
                "Le lien doit provenir de docs.google.com ou spreadsheets.google.com."
            )

        lower_input = normalized_input.lower()

        def _merge_params(*dicts: Dict[str, List[str]]) -> Dict[str, List[str]]:
            merged: Dict[str, List[str]] = {}
            for source in dicts:
                for key, values in source.items():
                    if not values:
                        continue
                    merged[key] = values
            return merged

        if "/export" in parsed.path.lower() and not normalized_sheet:
            export_params = _merge_params(parse_qs(parsed.query, keep_blank_values=True))
            export_params["format"] = ["csv"]
            normalized_query = urlencode(export_params, doseq=True)
            return urlunparse(parsed._replace(query=normalized_query))

        if "/gviz/tq" in parsed.path.lower():
            query_params = _merge_params(
                parse_qs(parsed.query, keep_blank_values=True),
                parse_qs(parsed.fragment, keep_blank_values=True) if parsed.fragment else {},
            )
            query_params["tqx"] = ["out:csv"]
            if normalized_sheet:
                query_params.pop("gid", None)
                query_params["sheet"] = [normalized_sheet]
            normalized_query = urlencode(query_params, doseq=True)
            return urlunparse(parsed._replace(query=normalized_query))

        if "/pub" in parsed.path.lower():
            pub_params = _merge_params(parse_qs(parsed.query, keep_blank_values=True))
            pub_params["output"] = ["csv"]
            normalized_query = urlencode(pub_params, doseq=True)
            return urlunparse(parsed._replace(query=normalized_query, path=re.sub(r"/pub(html)?$", "/pub", parsed.path)))

        if "export?format=" in lower_input and not normalized_sheet:
            export_params = _merge_params(parse_qs(parsed.query, keep_blank_values=True))
            export_params["format"] = ["csv"]
            normalized_query = urlencode(export_params, doseq=True)
            return urlunparse(parsed._replace(query=normalized_query))

        match = re.search(
            r"/spreadsheets/(?:u/\d+/)?d/(?:(?P<prefix>e)/)?(?P<id>[a-zA-Z0-9-_]+)",
            parsed.path,
        )
        if not match:
            raise ValueError("Impossible d'identifier l'identifiant du document.")

        document_id = match.group("id")
        has_published_prefix = match.group("prefix") == "e"
        document_path = (
            f"/spreadsheets/d/{'e/' if has_published_prefix else ''}{document_id}"
        )
        query_params = parse_qs(parsed.query, keep_blank_values=True)
        fragment_params = parse_qs(parsed.fragment, keep_blank_values=True) if parsed.fragment else {}
        merged_params = _merge_params(query_params, fragment_params)
        gid = (merged_params.get("gid") or [None])[0]

        if normalized_sheet:
            gviz_params = merged_params.copy()
            gviz_params["tqx"] = ["out:csv"]
            gviz_params.pop("gid", None)
            gviz_params["sheet"] = [normalized_sheet]
            gviz_query = urlencode(gviz_params, doseq=True)
            return urlunparse(
                (
                    parsed.scheme,
                    "docs.google.com",
                    f"{document_path}/gviz/tq",
                    "",
                    gviz_query,
                    "",
                )
            )

        export_params = merged_params.copy()
        export_params["format"] = ["csv"]
        normalized_query = urlencode(export_params, doseq=True)
        return urlunparse(
            (
                parsed.scheme,
                "docs.google.com",
                f"{document_path}/export",
                "",
                normalized_query,
                "",
            )
        )

    @staticmethod
    def _parse_bool(value: Any) -> Optional[bool]:
        """Convertit une entr√©e utilisateur en bool√©en si possible."""
        if isinstance(value, bool):
            return value
        if value is None or (isinstance(value, str) and value.strip() == ""):
            return None
        if pd.isna(value):
            return None

        if isinstance(value, (int, float)):
            if value == 1 or value == 1.0:
                return True
            if value == 0 or value == 0.0:
                return False

        if isinstance(value, str):
            normalized = value.strip().lower()
            if normalized in {"true", "1", "yes", "y", "vrai", "oui"}:
                return True
            if normalized in {"false", "0", "no", "n", "faux", "non"}:
                return False
        return None

    def _validate_manual_input(self, df: pd.DataFrame, schema: Dict[str, Any]) -> Tuple[pd.DataFrame, Dict[str, str]]:
        """Valide et convertit les valeurs saisies pour la pr√©diction manuelle."""
        cleaned_df = df.copy()
        errors: Dict[str, str] = {}

        for column, dtype in schema.items():
            if column not in cleaned_df.columns:
                continue

            series = cleaned_df[column]

            if pd.api.types.is_numeric_dtype(dtype):
                converted = pd.to_numeric(series, errors="coerce")
                non_empty = series.apply(self._is_non_empty_value)
                invalid_mask = non_empty & converted.isna()
                if invalid_mask.any():
                    errors[column] = f"{invalid_mask.sum()} valeur(s) non num√©riques"
                cleaned_df[column] = converted
            elif pd.api.types.is_datetime64_any_dtype(dtype):
                converted = pd.to_datetime(series, errors="coerce")
                non_empty = series.apply(self._is_non_empty_value)
                invalid_mask = non_empty & converted.isna()
                if invalid_mask.any():
                    errors[column] = f"{invalid_mask.sum()} valeur(s) de date invalides"
                cleaned_df[column] = converted
            elif pd.api.types.is_bool_dtype(dtype):
                converted_values = []
                invalid_count = 0
                for value in series:
                    parsed = self._parse_bool(value)
                    if parsed is None:
                        if self._is_non_empty_value(value):
                            invalid_count += 1
                        converted_values.append(None)
                    else:
                        converted_values.append(parsed)
                if invalid_count:
                    errors[column] = f"{invalid_count} valeur(s) non bool√©ennes"
                cleaned_df[column] = converted_values

        return cleaned_df, errors

    def _simulate_predictions(self, df: pd.DataFrame) -> pd.DataFrame:
        """G√©n√®re des pr√©dictions simul√©es reproductibles √† partir des donn√©es saisies."""
        if df.empty:
            return pd.DataFrame()

        reference_df = df.copy()
        for column in reference_df.columns:
            reference_df[column] = reference_df[column].apply(
                lambda value: "" if pd.isna(value) else value
            )
        hashed = pd.util.hash_pandas_object(reference_df, index=False).astype('uint64')
        normalized = (hashed % np.uint64(10000)).astype('float64') / 10000.0

        target_name = st.session_state.selected_target or "target"
        task_type = st.session_state.selected_task_type or "Classification"

        results_df = df.copy()

        if "R√©gression" in task_type:
            stats = st.session_state.target_stats or {}
            mean_value = stats.get("mean", 0.0)
            std_value = stats.get("std", 1.0)
            if std_value == 0.0:
                std_value = 1.0
            predictions = mean_value + (normalized - 0.5) * 2 * std_value
            results_df[f"prediction_{target_name}"] = np.round(predictions, 4)
        else:
            classes = st.session_state.target_classes or ["Classe 0", "Classe 1"]
            if not classes:
                classes = ["Classe 0", "Classe 1"]
            mapped_predictions = [
                classes[int(val * len(classes)) % len(classes)] for val in normalized
            ]
            results_df[f"prediction_{target_name}"] = mapped_predictions
            results_df["score"] = np.round(normalized, 4)

        return results_df

    def _step_data_loading(self):
        """√âtape 1: Chargement des donn√©es."""
        st.header("üì§ Chargement des donn√©es")
        st.write("Commencez par charger vos donn√©es pour l'entra√Ænement du mod√®le.")

        # S√©lection de la source de donn√©es
        data_source = st.selectbox(
            "Source de donn√©es",
            ["üìÅ Fichier local", "üìä Excel", "üìã Google Sheets", "ü§ù CRM", "üóÑÔ∏è Base de donn√©es"]
        )
        
        if data_source == "üìÅ Fichier local":
            uploaded_file = st.file_uploader(
                "Choisir un fichier",
                type=['csv', 'xlsx', 'xls', 'parquet', 'json'],
                help="Formats support√©s: CSV, Excel, Parquet, JSON"
            )
            if uploaded_file:
                with st.spinner("Chargement des donn√©es..."):
                    df = DataLoader.load_from_file(uploaded_file)
                    if df is not None:
                        self._display_loaded_data(df, "le fichier local")

        elif data_source == "üìä Excel":
            uploaded_excel = st.file_uploader(
                "Importer un classeur Excel",
                type=['xlsx', 'xls'],
                help="Chargez un fichier Excel et choisissez la feuille √† importer."
            )

            if uploaded_excel is not None:
                excel_bytes = uploaded_excel.getvalue()
                try:
                    workbook = pd.ExcelFile(BytesIO(excel_bytes))
                    sheet_name = st.selectbox(
                        "S√©lectionnez la feuille",
                        workbook.sheet_names,
                        key="excel_sheet_selector"
                    )

                    if sheet_name:
                        with st.spinner("Chargement de la feuille Excel..."):
                            df = pd.read_excel(BytesIO(excel_bytes), sheet_name=sheet_name)
                            self._display_loaded_data(df, f"Excel - feuille '{sheet_name}'")
                except Exception as exc:
                    st.error(f"Erreur lors de la lecture du fichier Excel : {exc}")

        elif data_source == "üìã Google Sheets":
            st.write("Connectez une feuille Google Sheets en fournissant un lien de partage public.")
            raw_url = st.text_input(
                "URL Google Sheets",
                placeholder="https://docs.google.com/spreadsheets/d/.../edit#gid=0"
            )

            if raw_url:
                sheet_hint = st.text_input(
                    "Nom de la feuille (optionnel)",
                    help="Utilis√© pour cibler une feuille sp√©cifique lorsque le lien n'indique pas de gid."
                )

                if st.button("üîÑ Charger la feuille", key="load_google_sheet", type="primary"):
                    try:
                        export_url = self._google_sheets_csv_url(
                            raw_url,
                            sheet_hint.strip() or None if sheet_hint else None
                        )
                    except ValueError as exc:
                        st.error(f"URL Google Sheets invalide : {exc}")
                    else:
                        with st.spinner("Chargement depuis Google Sheets..."):
                            try:
                                response = requests.get(export_url, timeout=15)
                                response.raise_for_status()
                                df = pd.read_csv(BytesIO(response.content))
                                self._display_loaded_data(df, "Google Sheets")
                            except requests.RequestException as exc:
                                st.error(
                                    "Impossible d'acc√©der √† la feuille. V√©rifiez les droits de partage et le lien fourni. "
                                    f"D√©tail : {exc}"
                                )
                            except Exception as exc:
                                st.error(
                                    "Le contenu t√©l√©charg√© n'a pas pu √™tre lu en tant que CSV. "
                                    f"D√©tail : {exc}"
                                )

        elif data_source == "üóÑÔ∏è Base de donn√©es":
            st.write("Interrogez une base SQL en utilisant une cha√Æne de connexion SQLAlchemy.")
            mask_connection = st.checkbox(
                "Masquer la cha√Æne de connexion",
                value=True,
                help="D√©cochez pour afficher la valeur saisie et v√©rifier la syntaxe."
            )
            connection_url = st.text_input(
                "Cha√Æne de connexion",
                placeholder="dialect+driver://user:password@host:port/database",
                type="password" if mask_connection else "default"
            )
            query = st.text_area(
                "Requ√™te SQL",
                value="SELECT * FROM information_schema.tables LIMIT 100"
            )

            if st.button("üîå Charger depuis la base", type="primary"):
                if not connection_url:
                    st.warning("Veuillez renseigner une cha√Æne de connexion valide.")
                elif not query.strip():
                    st.warning("Veuillez saisir une requ√™te SQL √† ex√©cuter.")
                else:
                    with st.spinner("Ex√©cution de la requ√™te..."):
                        try:
                            engine = create_engine(connection_url)
                            try:
                                with engine.connect() as connection:
                                    df = pd.read_sql_query(query, con=connection)
                            finally:
                                engine.dispose()
                            self._display_loaded_data(df, "la base de donn√©es")
                        except Exception as exc:
                            st.error(
                                "Connexion ou ex√©cution impossible. V√©rifiez les identifiants et la requ√™te. "
                                f"D√©tail : {exc}"
                            )

        else:
            st.info(f"{data_source} - Fonctionnalit√© en d√©veloppement")
        
        # Navigation
        st.markdown("---")
        col1, col2, col3 = st.columns([1, 1, 1])
        with col1:
            if st.button("üè† Retour √† l'accueil", use_container_width=True):
                st.switch_page("dashboard.py")
        with col3:
            if st.session_state.uploaded_data is not None:
                if st.button("Suivant ‚û°Ô∏è", type="primary", use_container_width=True):
                    st.session_state.wizard_step = 1
                    st.rerun()
    
    def _step_target_selection(self):
        """√âtape 2: S√©lection de la cible."""
        st.header("üéØ S√©lection de l'objectif")
        st.write("Choisissez la colonne que vous souhaitez pr√©dire.")
        
        if st.session_state.uploaded_data is None:
            st.warning("‚ö†Ô∏è Veuillez d'abord charger des donn√©es")
            if st.button("‚¨ÖÔ∏è Retour", use_container_width=True):
                st.session_state.wizard_step = 0
                st.rerun()
            return
        
        df = st.session_state.uploaded_data
        columns = df.columns.tolist()
        
        # S√©lection de la colonne cible
        previous_target = st.session_state.selected_target

        target_col = st.selectbox(
            "Colonne cible (√† pr√©dire)",
            ["S√©lectionner..."] + columns,
            help="S√©lectionnez la colonne que vous souhaitez pr√©dire"
        )

        if target_col and target_col != "S√©lectionner...":
            st.session_state.selected_target = target_col

            if previous_target and previous_target != target_col:
                self._reset_manual_prediction_state()

            # Analyse de la cible
            col1, col2 = st.columns(2)

            with col1:
                # D√©tection du type de t√¢che
                unique_values = df[target_col].nunique()
                if unique_values == 2:
                    task_type = "Classification binaire"
                    st.success(f"‚úÖ Type: **{task_type}**")
                elif unique_values < 10:
                    task_type = "Classification multi-classes"
                    st.info(f"‚ÑπÔ∏è Type: **{task_type}**")
                else:
                    task_type = "R√©gression"
                    st.info(f"‚ÑπÔ∏è Type: **{task_type}**")

                st.session_state.selected_task_type = task_type

                target_series = df[target_col].dropna()
                if "Classification" in task_type:
                    st.session_state.target_classes = list(pd.unique(target_series))[:50]
                    st.session_state.target_stats = {}
                else:
                    mean_value = float(target_series.mean()) if not target_series.empty else 0.0
                    std_value = float(target_series.std()) if len(target_series) > 1 else 0.0
                    if math.isnan(std_value):
                        std_value = 0.0
                    st.session_state.target_classes = []
                    st.session_state.target_stats = {"mean": mean_value, "std": std_value}

                st.metric("Valeurs uniques", unique_values)
                st.metric("Valeurs manquantes", df[target_col].isna().sum())
            
            with col2:
                # Distribution de la cible
                st.write("**Distribution de la cible**")
                if unique_values < 20:
                    fig = px.histogram(df, x=target_col, title=f"Distribution de {target_col}")
                else:
                    fig = px.box(df, y=target_col, title=f"Distribution de {target_col}")
                st.plotly_chart(fig, use_container_width=True)
        
        # Navigation
        st.markdown("---")
        col1, col2, col3 = st.columns([1, 1, 1])
        with col1:
            if st.button("‚¨ÖÔ∏è Retour", use_container_width=True):
                st.session_state.wizard_step = 0
                st.rerun()
        with col3:
            if st.session_state.selected_target:
                if st.button("Suivant ‚û°Ô∏è", type="primary", use_container_width=True):
                    st.session_state.wizard_step = 2
                    st.rerun()
    
    def _step_model_configuration(self):
        """√âtape 3: Configuration du mod√®le."""
        st.header("‚öôÔ∏è Configuration du mod√®le")
        st.write("Choisissez les param√®tres pour l'entra√Ænement de votre mod√®le.")
        
        # Mode de configuration
        config_mode = st.radio(
            "Mode de configuration",
            ["üöÄ Simplifi√© (Recommand√©)", "üéì Expert"],
            horizontal=True
        )
        
        if config_mode == "üöÄ Simplifi√© (Recommand√©)":
            # Mode simplifi√©
            optimization_level = st.select_slider(
                "Niveau d'optimisation",
                options=["‚ö° Rapide", "‚öñÔ∏è √âquilibr√©", "üöÄ Maximum"],
                value="‚öñÔ∏è √âquilibr√©",
                help="Rapide: 5 min | √âquilibr√©: 15 min | Maximum: 45+ min"
            )
            
            # Affichage de la configuration
            if optimization_level == "‚ö° Rapide":
                st.info("**Configuration rapide**\n- 3 algorithmes\n- 10 it√©rations d'optimisation\n- Validation crois√©e: 3 folds")
                config = {"algorithms": 3, "iterations": 10, "cv_folds": 3}
            elif optimization_level == "‚öñÔ∏è √âquilibr√©":
                st.info("**Configuration √©quilibr√©e**\n- 5 algorithmes\n- 30 it√©rations d'optimisation\n- Validation crois√©e: 5 folds")
                config = {"algorithms": 5, "iterations": 30, "cv_folds": 5}
            else:
                st.info("**Configuration maximale**\n- 8 algorithmes\n- 100 it√©rations d'optimisation\n- Validation crois√©e: 5 folds")
                config = {"algorithms": 8, "iterations": 100, "cv_folds": 5}
            
            # Options suppl√©mentaires
            with st.expander("Options suppl√©mentaires"):
                st.checkbox("G√©rer les classes d√©s√©quilibr√©es", value=True, key="handle_imbalance")
                st.checkbox("G√©n√©rer des explications (SHAP)", value=True, key="explain")
                st.checkbox("Feature engineering automatique", value=False, key="feature_eng")
        
        else:
            # Mode expert
            st.warning("üéì Mode expert - Configuration manuelle avanc√©e")
            
            tabs = st.tabs(["Algorithmes", "Hyperparam√®tres", "Validation"])
            
            with tabs[0]:
                st.write("**S√©lection des algorithmes**")
                col1, col2 = st.columns(2)
                with col1:
                    st.checkbox("XGBoost", value=True, key="algo_xgb")
                    st.checkbox("LightGBM", value=True, key="algo_lgb")
                    st.checkbox("CatBoost", value=False, key="algo_cat")
                    st.checkbox("Random Forest", value=True, key="algo_rf")
                with col2:
                    st.checkbox("Logistic/Linear Regression", value=True, key="algo_lr")
                    st.checkbox("SVM", value=False, key="algo_svm")
                    st.checkbox("Neural Network", value=False, key="algo_nn")
                    st.checkbox("Extra Trees", value=False, key="algo_et")
            
            with tabs[1]:
                st.write("**Optimisation des hyperparam√®tres**")
                st.selectbox("M√©thode", ["Optuna", "Grid Search", "Random Search", "Bayesian"])
                st.number_input("Nombre d'it√©rations", value=50, min_value=10, max_value=500)
                st.checkbox("Early stopping", value=True)
            
            with tabs[2]:
                st.write("**Strat√©gie de validation**")
                st.selectbox("Type", ["Stratified K-Fold", "K-Fold", "Time Series Split"])
                st.slider("Nombre de folds", 2, 10, 5)
                st.slider("Taille du test (%)", 10, 40, 20)
            
            config = {"mode": "expert"}
        
        st.session_state.training_config = config
        
        # Navigation
        st.markdown("---")
        col1, col2, col3 = st.columns([1, 1, 1])
        with col1:
            if st.button("‚¨ÖÔ∏è Retour", use_container_width=True):
                st.session_state.wizard_step = 1
                st.rerun()
        with col3:
            if st.button("Lancer l'entra√Ænement üöÄ", type="primary", use_container_width=True):
                st.session_state.wizard_step = 3
                st.rerun()
    
    def _step_training(self):
        """√âtape 4: Entra√Ænement."""
        st.header("üöÄ Entra√Ænement en cours")
        st.write("Votre mod√®le est en cours d'entra√Ænement...")
        
        # Conteneurs pour l'affichage dynamique
        progress_container = st.container()
        status_container = st.container()
        metrics_container = st.container()
        
        with progress_container:
            progress_bar = st.progress(0)
        
        with status_container:
            status_text = st.empty()
        
        # Simulation de l'entra√Ænement
        steps = [
            ("üîß Pr√©paration des donn√©es", 0.15),
            ("üîç Feature engineering", 0.30),
            ("üìà Entra√Ænement XGBoost", 0.45),
            ("üìä Entra√Ænement LightGBM", 0.60),
            ("‚öôÔ∏è Optimisation des hyperparam√®tres", 0.80),
            ("‚úÖ √âvaluation finale", 1.0)
        ]
        
        for step_name, progress_value in steps:
            status_text.text(f"{step_name}...")
            progress_bar.progress(progress_value)
            time.sleep(0.5)  # Simulation du temps de traitement
        
        status_text.success("‚úÖ Entra√Ænement termin√© avec succ√®s!")
        st.balloons()
        
        # M√©triques de performance
        with metrics_container:
            st.subheader("üìä Performances obtenues")
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Accuracy", "94.2%", "+2.1%")
            with col2:
                st.metric("Precision", "93.8%", "+1.8%")
            with col3:
                st.metric("Recall", "94.6%", "+2.4%")
            with col4:
                st.metric("F1-Score", "94.2%", "+2.1%")
            
            st.info("‚è±Ô∏è Temps total d'entra√Ænement: **12 minutes 34 secondes**")
        
        # Navigation
        st.markdown("---")
        col1, col2, col3 = st.columns([1, 1, 1])
        with col3:
            if st.button("Voir les r√©sultats ‚û°Ô∏è", type="primary", use_container_width=True):
                st.session_state.wizard_step = 4
                st.rerun()
    
    def _step_results(self):
        """√âtape 5: R√©sultats."""
        st.header("üìä R√©sultats")
        st.write("Analyse d√©taill√©e des performances de votre mod√®le.")
        
        # Tabs pour diff√©rentes vues
        tabs = st.tabs(["üìà Performance", "üéØ Feature Importance", "üîÆ Pr√©dictions", "üíæ Export"])
        
        with tabs[0]:
            st.subheader("Performance du mod√®le")
            
            # Graphique de comparaison Train/Test
            fig = go.Figure(data=[
                go.Bar(name='Train', x=['Accuracy', 'Precision', 'Recall', 'F1-Score'], 
                      y=[0.96, 0.95, 0.97, 0.96]),
                go.Bar(name='Test', x=['Accuracy', 'Precision', 'Recall', 'F1-Score'], 
                      y=[0.94, 0.94, 0.95, 0.94])
            ])
            fig.update_layout(
                barmode='group',
                title="Comparaison Train vs Test",
                yaxis_title="Score",
                showlegend=True
            )
            st.plotly_chart(fig, use_container_width=True)
            
            # Matrice de confusion simul√©e
            st.write("**Matrice de confusion**")
            confusion_matrix = [[850, 50], [30, 70]]
            fig_cm = px.imshow(
                confusion_matrix,
                labels=dict(x="Pr√©diction", y="R√©alit√©", color="Nombre"),
                x=['Classe 0', 'Classe 1'],
                y=['Classe 0', 'Classe 1'],
                text_auto=True
            )
            st.plotly_chart(fig_cm, use_container_width=True)
        
        with tabs[1]:
            st.subheader("Importance des features")
            
            # Graphique d'importance simul√©
            features = ['Feature A', 'Feature B', 'Feature C', 'Feature D', 'Feature E', 
                       'Feature F', 'Feature G', 'Feature H']
            importance = [0.25, 0.20, 0.15, 0.12, 0.10, 0.08, 0.06, 0.04]
            
            fig = px.bar(
                x=importance, 
                y=features, 
                orientation='h',
                title="Top 8 Features les plus importantes",
                labels={'x': 'Importance', 'y': 'Features'}
            )
            st.plotly_chart(fig, use_container_width=True)
            
            st.info("üí° Les features A, B et C contribuent √† 60% de la performance du mod√®le")
        
        with tabs[2]:
            st.subheader("Faire des pr√©dictions")
            st.write("Utilisez votre mod√®le entra√Æn√© pour faire de nouvelles pr√©dictions.")
            
            prediction_method = st.radio(
                "M√©thode de pr√©diction",
                ["üì§ Uploader un fichier", "‚úèÔ∏è Saisie manuelle"],
                horizontal=True
            )
            
            if prediction_method == "üì§ Uploader un fichier":
                uploaded_pred = st.file_uploader(
                    "Choisir un fichier pour les pr√©dictions",
                    type=['csv', 'xlsx'],
                    key="pred_file"
                )
                if uploaded_pred:
                    st.success("Fichier charg√© - Pr√™t pour les pr√©dictions")
                    if st.button("üîÆ Lancer les pr√©dictions", type="primary"):
                        with st.spinner("Pr√©dictions en cours..."):
                            time.sleep(2)
                        st.success("‚úÖ Pr√©dictions termin√©es!")
                        st.download_button(
                            "üì• T√©l√©charger les r√©sultats",
                            data="prediction,probability\n0,0.92\n1,0.15\n0,0.88",
                            file_name="predictions.csv",
                            mime="text/csv"
                        )
            else:
                st.write(
                    "Cr√©ez un petit jeu de donn√©es de pr√©diction en √©ditant le tableau ci-dessous."
                )

                feature_columns: List[str] = []
                schema: Dict[str, Any] = {}
                previous_columns = list(st.session_state.manual_prediction_columns)

                if st.session_state.uploaded_data is not None:
                    feature_columns = [
                        col for col in st.session_state.uploaded_data.columns
                        if not st.session_state.selected_target or col != st.session_state.selected_target
                    ]
                    if feature_columns:
                        st.caption(
                            "Les colonnes sont pr√©-remplies √† partir des donn√©es d'entra√Ænement charg√©es."
                        )
                    else:
                        st.warning(
                            "Aucune colonne de caract√©ristiques disponible. V√©rifiez la colonne cible s√©lectionn√©e."
                        )

                manual_columns_entry = st.text_input(
                    "Colonnes de caract√©ristiques (s√©par√©es par des virgules)",
                    value=", ".join(st.session_state.manual_prediction_columns)
                    if st.session_state.manual_prediction_columns and not feature_columns
                    else "",
                    help=(
                        "Pr√©cisez les colonnes √† utiliser pour la pr√©diction lorsque aucune donn√©e n'a √©t√© charg√©e."
                    ),
                    key="manual_prediction_columns_input",
                    disabled=bool(feature_columns)
                )

                if manual_columns_entry and not feature_columns:
                    parsed_columns = [
                        col.strip() for col in manual_columns_entry.split(",") if col.strip()
                    ]
                    feature_columns = parsed_columns
                    if parsed_columns != previous_columns:
                        st.session_state.manual_prediction_columns = parsed_columns
                        schema = {col: object for col in parsed_columns}
                        st.session_state.manual_prediction_schema = schema
                        st.session_state.manual_prediction_validation_errors = {}
                        st.session_state.manual_prediction_df = None
                    else:
                        schema = st.session_state.manual_prediction_schema
                elif feature_columns:
                    if feature_columns != previous_columns:
                        st.session_state.manual_prediction_columns = feature_columns
                        schema = {
                            col: st.session_state.uploaded_data[col].dtype
                            if st.session_state.uploaded_data is not None and col in st.session_state.uploaded_data.columns
                            else object
                            for col in feature_columns
                        }
                        st.session_state.manual_prediction_schema = schema
                        st.session_state.manual_prediction_validation_errors = {}
                        st.session_state.manual_prediction_df = None
                    else:
                        schema = st.session_state.manual_prediction_schema

                if not st.session_state.manual_prediction_columns:
                    st.info(
                        "Ajoutez au moins une colonne pour saisir des donn√©es de pr√©diction."
                    )
                    st.session_state.manual_prediction_df = pd.DataFrame()
                else:
                    manual_df = st.session_state.manual_prediction_df
                    if (
                        manual_df is None
                        or list(manual_df.columns) != st.session_state.manual_prediction_columns
                    ):
                        manual_df = pd.DataFrame([
                            {
                                col: self._default_value_for_dtype(
                                    st.session_state.manual_prediction_schema.get(col)
                                )
                                for col in st.session_state.manual_prediction_columns
                            }
                        ])

                    edited_df = st.data_editor(
                        manual_df,
                        num_rows="dynamic",
                        use_container_width=True,
                        key="manual_prediction_editor",
                        column_config=self._build_column_configs(
                            st.session_state.manual_prediction_schema
                        ),
                    )

                    if len(edited_df) > 500:
                        st.warning(
                            "Seules les 500 premi√®res lignes seront conserv√©es pour les pr√©dictions manuelles."
                        )
                        edited_df = edited_df.head(500)

                    st.session_state.manual_prediction_df = edited_df

                    validation_errors = st.session_state.manual_prediction_validation_errors
                    if validation_errors:
                        error_box = st.container()
                        with error_box:
                            st.error("Certaines valeurs doivent √™tre corrig√©es avant de lancer les pr√©dictions :")
                            for col_name, message in validation_errors.items():
                                st.markdown(f"- **{col_name}** : {message}")

                    actions_col1, actions_col2 = st.columns(2)
                    with actions_col1:
                        if st.button("‚ôªÔ∏è R√©initialiser la saisie", use_container_width=True):
                            self._reset_manual_prediction_state()
                            st.rerun()
                    with actions_col2:
                        if st.button(
                            "üîÆ Lancer les pr√©dictions (saisie)",
                            type="primary",
                            use_container_width=True
                        ):
                            cleaned_df, errors = self._validate_manual_input(
                                edited_df,
                                st.session_state.manual_prediction_schema
                            )

                            if errors:
                                st.session_state.manual_prediction_validation_errors = errors
                                st.warning(
                                    "Corrigez les colonnes signal√©es avant de lancer les pr√©dictions."
                                )
                            else:
                                st.session_state.manual_prediction_validation_errors = {}
                                st.session_state.manual_prediction_df = cleaned_df
                                ready_df = cleaned_df.dropna(how="all")

                                if ready_df.empty:
                                    st.warning(
                                        "Ajoutez au moins une ligne avec des valeurs pour lancer les pr√©dictions."
                                    )
                                else:
                                    with st.spinner("Pr√©dictions en cours..."):
                                        time.sleep(2)

                                    results_df = self._simulate_predictions(ready_df)
                                    st.session_state.manual_prediction_results = results_df

                                    st.success("‚úÖ Pr√©dictions simul√©es pr√™tes √† √™tre examin√©es")
                                    st.dataframe(results_df, use_container_width=True)
                                    st.download_button(
                                        "üì• T√©l√©charger les r√©sultats",
                                        data=results_df.to_csv(index=False).encode("utf-8"),
                                        file_name="predictions_manuel.csv",
                                        mime="text/csv"
                                    )

                if st.session_state.manual_prediction_results is not None:
                    with st.expander("Derniers r√©sultats g√©n√©r√©s", expanded=False):
                        st.dataframe(
                            st.session_state.manual_prediction_results,
                            use_container_width=True
                        )
        
        with tabs[3]:
            st.subheader("Export du mod√®le")
            st.write("T√©l√©chargez votre mod√®le entra√Æn√© ou d√©ployez-le en production.")
            
            col1, col2 = st.columns(2)
            with col1:
                st.write("**üì¶ Export local**")
                st.button("üì• T√©l√©charger (.pkl)", use_container_width=True)
                st.button("üì• T√©l√©charger (.onnx)", use_container_width=True)
                st.button("üìÑ G√©n√©rer rapport PDF", use_container_width=True)
            
            with col2:
                st.write("**‚òÅÔ∏è D√©ploiement**")
                st.button("üöÄ D√©ployer sur API", use_container_width=True, type="primary")
                st.button("üê≥ G√©n√©rer Docker", use_container_width=True)
                st.button("‚ò∏Ô∏è D√©ployer sur Kubernetes", use_container_width=True)
        
        # Navigation finale
        st.markdown("---")
        col1, col2, col3 = st.columns([1, 1, 1])
        with col1:
            if st.button("üîÑ Nouveau projet", use_container_width=True):
                # R√©initialiser l'√©tat
                st.session_state.wizard_step = 0
                st.session_state.uploaded_data = None
                st.session_state.selected_target = None
                st.session_state.training_config = {}
                st.session_state.selected_task_type = None
                st.session_state.target_classes = []
                st.session_state.target_stats = {}
                self._reset_manual_prediction_state()
                st.rerun()
        with col2:
            if st.button("üè† Retour √† l'accueil", use_container_width=True):
                st.switch_page("dashboard.py")
        with col3:
            if st.button("üìä Voir le monitoring", use_container_width=True):
                st.info("Page monitoring en d√©veloppement")


def main():
    """Point d'entr√©e principal de la page wizard."""
    # Initialisation de l'√©tat
    SessionState.initialize()
    
    # Sidebar
    with st.sidebar:
        st.image("https://via.placeholder.com/300x100/1E88E5/FFFFFF?text=AutoML+Platform", 
                use_container_width=True)
        
        st.divider()
        
        # Informations sur l'√©tape actuelle
        st.markdown("### üìç Navigation")
        st.info(f"√âtape actuelle: **{st.session_state.wizard_step + 1}/5**")
        
        # Actions rapides
        st.markdown("### ‚ö° Actions rapides")
        if st.button("üè† Accueil", use_container_width=True):
            st.switch_page("dashboard.py")
        if st.button("üîÑ R√©initialiser", use_container_width=True):
            st.session_state.wizard_step = 0
            st.session_state.uploaded_data = None
            st.session_state.selected_target = None
            st.session_state.training_config = {}
            st.session_state.selected_task_type = None
            st.session_state.target_classes = []
            st.session_state.target_stats = {}
            wizard = AutoMLWizard()
            wizard._reset_manual_prediction_state()
            st.rerun()
        
        st.divider()
        
        # Aide
        with st.expander("‚ùì Aide"):
            st.markdown("""
            **Guide de l'assistant:**
            1. **Chargement**: Importez vos donn√©es
            2. **Objectif**: S√©lectionnez la cible √† pr√©dire
            3. **Configuration**: Choisissez les param√®tres
            4. **Entra√Ænement**: Lancez l'apprentissage
            5. **R√©sultats**: Analysez les performances
            
            **Support:**
            - üìß support@automl.com
            - üìû +33 1 23 45 67 89
            """)
    
    # Contenu principal
    wizard = AutoMLWizard()
    wizard.render()


if __name__ == "__main__":
    main()
