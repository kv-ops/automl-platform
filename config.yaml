# ==============================================================================
# Configuration AutoML Platform
# Compatible with automl_platform structure
# Version: 3.2.1
# ==============================================================================

# Environment settings
environment: development
debug: true
verbose: true
random_state: 42
n_jobs: -1

# ---------- Database Configuration ----------
database:
  url: sqlite:///automl.db
  audit_url: null
  rgpd_url: null

# ---------- Storage Configuration ----------
storage:
  backend: local  # Options: local, minio, s3, gcs
  local_base_path: ./ml_storage
  
  # MinIO/S3 settings
  endpoint: localhost:9000
  access_key: ${MINIO_ACCESS_KEY}
  secret_key: ${MINIO_SECRET_KEY}
  secure: false
  region: us-east-1
  
  # GCS settings (if backend = gcs)
  project_id: ${GCP_PROJECT_ID}
  credentials_path: ${GOOGLE_APPLICATION_CREDENTIALS}
  
  # Buckets/containers
  models_bucket: models
  datasets_bucket: datasets
  artifacts_bucket: artifacts
  
  # Features
  enable_feature_store: true
  auto_versioning: true
  max_versions_per_model: 10

# ---------- API Configuration ----------
api:
  enabled: true
  host: 0.0.0.0
  port: 8000
  
  # Security
  enable_auth: false
  jwt_secret: ${JWT_SECRET_KEY}
  jwt_algorithm: HS256
  jwt_expiration_minutes: 60
  redis_url: redis://:${REDIS_PASSWORD:-devredis}@redis:6379/0
  
  # Rate limiting
  enable_rate_limit: true
  
  # CORS
  enable_cors: true
  cors_origins: ["*"]
  
  # Documentation
  enable_docs: true
  
  # File upload
  max_upload_size_mb: 100
  allowed_extensions: [".csv", ".parquet", ".json", ".xlsx"]

# ---------- Security ----------
security:
  secret_key: ${AUTOML_SECRET_KEY}

# ---------- Monitoring Configuration ----------
monitoring:
  enabled: true
  
  # Data quality
  min_quality_score: 70.0
  max_missing_ratio: 0.3
  max_outlier_ratio: 0.1
  
  # Drift detection
  drift_detection_enabled: true
  drift_check_frequency: 100
  drift_sensitivity: 0.05
  
  # Performance tracking
  track_performance: true
  performance_window_days: 7
  
  # Alerting
  alerting_enabled: true
  alert_channels: ["log"]
  
  # Notification settings (optional - uncomment to use)
  # slack_webhook_url: https://hooks.slack.com/services/YOUR/WEBHOOK/URL
  # email_smtp_host: smtp.gmail.com
  # email_smtp_port: 587
  # email_from: alerts@automl.com
  # email_recipients: []

# ---------- LLM Configuration ----------
llm:
  enabled: false  # Set to true when you have API keys

  # Provider settings
  provider: openai  # Options: openai, anthropic
  # api_key: sk-your-api-key  # Use environment variable OPENAI_API_KEY instead
  model_name: gpt-4
  temperature: 0.7
  max_tokens: 1000
  
  # Features
  enable_data_cleaning: true
  enable_feature_suggestions: true
  enable_model_explanations: true
  enable_chatbot: true
  
  # RAG settings
  enable_rag: true
  vector_store: chromadb
  embedding_model: text-embedding-ada-002
  
  # Caching
  cache_responses: true

# ---------- Agent-First & Hybrid Cleaning ----------
agent_first:
  enabled: true
  enable_hybrid_mode: true
  hybrid_mode_thresholds:
    missing_threshold: 0.35
    outlier_threshold: 0.10
    quality_score_threshold: 70.0
    complexity_threshold: 0.8
    cost_threshold: 1.0
  retail_rules:
    sentinel_values: [-999, -1, 9999]
    stock_zero_acceptable: true
    price_negative_critical: true
    sku_format_strict: true
    gs1_compliance_required: true
    gs1_compliance_target: 0.98
    category_imputation: by_category
    price_imputation: median_by_category
  hybrid_cost_limits:
    max_openai: 3.0
    max_claude: 2.0
    max_total: 5.0
    max_per_decision: 0.1
  sector_keywords:
    retail: ["SKU", "UPC", "GS1", "inventory", "merchandising"]
    finance: ["IFRS", "Basel", "risk management"]
    sante: ["HL7", "ICD-10", "patient data"]
    industrie: ["ISO", "manufacturing", "supply chain"]

# ---------- Worker Configuration ----------
worker:
  enabled: false  # Set to true for distributed processing
  backend: celery
  
  # Redis settings for Celery
  broker_url: redis://localhost:6379/0
  result_backend: redis://localhost:6379/0
  
  # Worker settings
  max_workers: 4
  max_concurrent_jobs: 2
  task_time_limit: 3600

# ---------- AutoML Training Configuration ----------
# Data preprocessing
max_missing_ratio: 0.5
rare_category_threshold: 0.01
high_cardinality_threshold: 20
outlier_method: iqr
outlier_threshold: 1.5
scaling_method: robust

# Feature engineering
create_polynomial: false
polynomial_degree: 2
create_interactions: false
create_datetime_features: true
enable_auto_feature_engineering: true
max_features_generated: 50

# Model selection
task: auto  # Options: classification, regression, auto
cv_folds: 5
scoring: auto
# Fixed: Use specific algorithm list instead of "all"
# Accepts marketing names (e.g. "XGBoost") or estimator identifiers (e.g. "XGBClassifier")
algorithms: ["XGBoost", "RandomForest", "LogisticRegression", "LightGBM", "CatBoost"]
exclude_algorithms: []

# Hyperparameter optimization
hpo_method: optuna
hpo_n_iter: 20
hpo_time_budget: 3600

# Ensemble methods
ensemble_method: voting
ensemble_use_probabilities: true

# Class imbalance handling
handle_imbalance: true
imbalance_method: class_weight

# Performance thresholds
min_accuracy: 0.6
min_auc: 0.6
min_r2: 0.0

# ---------- Output Settings ----------
output_dir: ./automl_output
save_pipeline: true
save_predictions: true
save_feature_importance: true
generate_report: true

# Output report format and export options
report_format: html  # 'html', 'pdf', or 'markdown'

# Export formats
# Disable Docker export in development since no Docker daemon is available in the API container.
enable_docker_export: false
enable_onnx_export: true
enable_pmml_export: false

# ---------- Resource Limits ----------
max_memory_gb: 16.0
max_time_minutes: 60
max_models_to_train: 50

# ---------- Multi-tenant Support ----------
tenant_id: default

# ---------- Logging Configuration ----------
log_level: INFO
log_file: ./logs/automl.log
log_to_mlflow: false

# ---------- Infrastructure Settings ----------
# Billing (requires database setup)
billing:
  enabled: false
  plan_type: free

# ---------- Data Connectors ----------
connectors:
  enabled: true
  default_connector: postgresql
  connectors:
    snowflake:
      account: ${SNOWFLAKE_ACCOUNT}
      username: ${SNOWFLAKE_USER}
      password: ${SNOWFLAKE_PASSWORD}
      warehouse: ${SNOWFLAKE_WAREHOUSE}
      database: ${SNOWFLAKE_DATABASE}
      schema: public
    bigquery:
      project_id: ${GCP_PROJECT_ID}
      dataset_id: ${BQ_DATASET_ID}
      credentials_path: ${GOOGLE_APPLICATION_CREDENTIALS}
    databricks:
      host: ${DATABRICKS_HOST}
      token: ${DATABRICKS_TOKEN}
      catalog: hive_metastore
      schema: default
    postgresql:
      host: ${PG_HOST:-localhost}
      port: ${PG_PORT:-5432}
      database: ${PG_DATABASE:-automl}
      username: ${PG_USER:-postgres}
      password: ${PG_PASSWORD}
    mongodb:
      host: ${MONGO_HOST:-localhost}
      port: ${MONGO_PORT:-27017}
      database: ${MONGO_DATABASE:-automl}
      username: ${MONGO_USER}
      password: ${MONGO_PASSWORD}

# ---------- Streaming ----------
streaming:
  enabled: false
  platform: kafka  # Options: kafka, pulsar, redis
  brokers: ["localhost:9092"]
