# AutoML Platform Configuration File
# This file centralizes all hyperparameters and settings

# ============== General Settings ==============
random_state: 42  # Seed for reproducibility
n_jobs: -1  # Number of parallel jobs (-1 = all cores)
verbose: 1  # Verbosity level (0=silent, 1=normal, 2=debug)

# ============== Data Preprocessing ==============
# Missing value handling
max_missing_ratio: 0.5  # Drop columns with > 50% missing
imputation_numeric: median  # Options: mean, median, mode
imputation_categorical: most_frequent  # Options: most_frequent, constant

# Categorical encoding
rare_category_threshold: 0.01  # Categories with < 1% frequency are "rare"
high_cardinality_threshold: 20  # Use target encoding if > 20 categories
encoding_method: auto  # Options: auto, onehot, target, label

# Outlier detection
outlier_method: iqr  # Options: iqr, isolation_forest, zscore, none
outlier_threshold: 1.5  # IQR multiplier for outlier detection
outlier_handling: clip  # Options: clip, remove, none

# Scaling
scaling_method: robust  # Options: standard, robust, minmax, none

# ============== Feature Engineering ==============
# Polynomial features
create_polynomial: false
polynomial_degree: 2
polynomial_interaction_only: false

# Interaction features
create_interactions: false
max_interactions: 10

# Datetime features
create_datetime_features: true
datetime_components:
  - year
  - month
  - day
  - dayofweek
  - quarter
  - is_weekend

# Lag features (for time series)
create_lag_features: false
lag_periods:
  - 1
  - 7
  - 30
rolling_windows:
  - 7
  - 30

# Text features
text_max_features: 100
text_ngram_range: [1, 2]
text_min_df: 2
text_max_df: 0.95

# ============== Model Selection ==============
# Task detection
task: auto  # Options: classification, regression, timeseries, auto

# Cross-validation
cv_folds: 5
validation_strategy: auto  # Options: stratified, kfold, timeseries, auto

# Scoring metric
scoring: auto  # Auto-selects based on task, or specify: accuracy, roc_auc, f1, rmse, r2

# ============== Hyperparameter Optimization ==============
# HPO method
hpo_method: optuna  # Options: grid, random, optuna, none
hpo_n_iter: 20  # Number of iterations for random/optuna
hpo_n_trials: 20  # For optuna
hpo_time_budget: 3600  # Max seconds for HPO
early_stopping_rounds: 50  # For boosting algorithms

# Optuna settings
optuna_sampler: tpe  # Options: tpe, random, grid
optuna_pruner: median  # Options: median, hyperband, none

# ============== Model Training ==============
# Algorithms to test
algorithms:
  - all  # Use "all" to test all available models
  # Or specify individual models:
  # - LogisticRegression
  # - RandomForestClassifier
  # - XGBClassifier
  # - LGBMClassifier

# Algorithms to exclude (even if in "all")
exclude_algorithms:
  - GaussianProcessClassifier  # Too slow
  - GaussianProcessRegressor  # Too slow
  - QuadraticDiscriminantAnalysis  # Memory intensive

# Ensemble settings
ensemble_method: voting  # Options: voting, stacking, none
ensemble_top_k: 3  # Use top k models for ensemble

# Calibration
calibrate_probabilities: false  # Calibrate prediction probabilities
calibration_method: isotonic  # Options: isotonic, sigmoid

# ============== Class Imbalance ==============
# Handling imbalanced datasets
handle_imbalance: true
imbalance_method: class_weight  # Options: class_weight, smote, adasyn, none
imbalance_threshold: 0.3  # Consider imbalanced if minority < 30%

# SMOTE settings
smote_k_neighbors: 5
smote_sampling_strategy: auto  # Options: auto, minority, not_majority

# ============== Performance Thresholds ==============
# Minimum acceptable metrics
min_accuracy: 0.6
min_auc: 0.6
min_r2: 0.0
min_f1: 0.5

# ============== Output Settings ==============
# Output directory
output_dir: ./automl_output

# What to save
save_pipeline: true
save_leaderboard: true
save_predictions: true
save_feature_importance: true
save_plots: true
generate_report: true

# Report format
report_format: html  # Options: html, pdf, markdown

# ============== API Settings ==============
# API configuration
api_enabled: false
api_host: 0.0.0.0
api_port: 8000
api_workers: 4
api_reload: true

# API authentication
api_auth_enabled: false
api_key: null

# ============== Monitoring ==============
# Drift detection
enable_drift_detection: true
drift_method: ks  # Options: ks, chi2, jensen_shannon
drift_threshold: 0.1

# Data quality checks
enable_quality_checks: true
quality_checks:
  - missing_values
  - duplicate_rows
  - constant_features
  - high_cardinality

# ============== Logging ==============
# Logging configuration
log_level: INFO  # Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
log_file: automl.log
log_format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

# ============== Advanced Settings ==============
# Memory optimization
max_memory_gb: null  # Limit memory usage (null = unlimited)
chunk_size: 10000  # Process data in chunks for large datasets

# Parallel processing
backend: loky  # Options: loky, threading, multiprocessing
max_parallel_models: 4  # Max models to train in parallel

# Caching
enable_caching: true
cache_dir: ./.cache

# Reproducibility
ensure_reproducibility: true
disable_gpu: false  # Force CPU even if GPU available

# ============== Experimental Features ==============
# Enable experimental features
enable_experimental: false

# AutoML search space expansion
auto_expand_search_space: false
search_space_multiplier: 2

# Neural architecture search (NAS)
enable_nas: false
nas_max_layers: 5
nas_max_neurons: 512

# Feature synthesis
enable_feature_synthesis: false
max_synthetic_features: 20

# ============== Custom Settings ==============
# Add your custom settings here
custom:
  project_name: AutoML_Project
  author: Data Science Team
  version: 1.0.0
