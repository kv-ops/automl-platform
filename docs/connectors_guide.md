# Guide de Configuration des Connecteurs AutoML Platform

## ‚òÅÔ∏è Google BigQuery

### 1. Pr√©parer le compte de service

1. Cr√©ez un projet ou s√©lectionnez un projet existant dans la [Google Cloud Console](https://console.cloud.google.com/).
2. Activez l'API **BigQuery** et **BigQuery Storage** (n√©cessaire pour les chargements rapides).
3. Dans *IAM & Admin ‚Üí Service Accounts*, cr√©ez un compte de service d√©di√©.
4. T√©l√©chargez la cl√© JSON **et** stockez-la de fa√ßon s√©curis√©e (Vault, Secret Manager, etc.).

### 2. Configuration s√©curis√©e

```bash
# Option 1 ‚Äî chemin vers le fichier (non recommand√© en production)
export GOOGLE_APPLICATION_CREDENTIALS="/chemin/vers/key.json"

# Option 2 ‚Äî JSON inline (recommand√© pour les d√©ploiements containeris√©s)
export GOOGLE_BIGQUERY_CREDENTIALS_JSON='{"type": "service_account", ...}'
```

```python
config = ConnectionConfig(
    connection_type='bigquery',
    project_id='mon-projet',
    dataset_id='mon_dataset',
    requests_per_minute=60,      # limite par d√©faut appliqu√©e par la plateforme
    max_retries=3,               # nombre de retries
    retry_backoff_seconds=1.0,   # backoff exponentiel avec jitter
)
connector = BigQueryConnector(config)
```

> üí° **Astuce s√©curit√©** : utilisez `credentials_json` (dictionnaire) si vous chargez la configuration depuis un secret manager afin d'√©viter toute √©criture sur disque.

### 3. Respect des quotas & co√ªts

- Limite par d√©faut : **60 requ√™tes/minute** par connecteur pour √©viter les d√©passements de quota.
- Ajustez `requests_per_minute` si vous disposez d'un quota personnalis√©.
- BigQuery facture chaque requ√™te : surveillez les volumes via les m√©triques `ml_connectors_data_volume_bytes`.

### 4. Gestion des erreurs

- Les op√©rations de lecture utilisent un retry exponentiel (`max_retries`, `retry_backoff_seconds`).
- Les √©critures utilisent un identifiant de job idempotent pour √©viter les doublons lors des retries.

---

## üî• Databricks SQL Warehouse

### 1. R√©cup√©rer les identifiants

1. Dans l'espace de travail Databricks ‚Üí *Settings ‚Üí Developer* : g√©n√©rez un **token personnel**.
2. Depuis votre entrep√¥t SQL, copiez le **Server Hostname** et le **HTTP Path**.

### 2. Configuration s√©curis√©e

```bash
export DATABRICKS_HOST="adb-12345.6.azuredatabricks.net"
export DATABRICKS_HTTP_PATH="/sql/1.0/warehouses/abcdef"
export DATABRICKS_TOKEN="dapiXXXXXXXXXXXXXXXX"
```

```python
config = ConnectionConfig(
    connection_type='databricks',
    catalog='main',
    schema='analytics',
    requests_per_minute=120,   # throttle automatique pour respecter les SLAs
    max_retries=2,
    retry_backoff_seconds=1.5,
)
connector = DatabricksConnector(config)
```

> üîê Aucun token n'est loggu√© et les valeurs peuvent √™tre fournies uniquement via les variables d'environnement ci-dessus.

### 3. Bonnes pratiques

- Les requ√™tes `SELECT` b√©n√©ficient du retry exponentiel automatique.
- Les inserts utilisent un commit explicite ; pour les charges sensibles, pr√©f√©rez un staging table + `MERGE` c√¥t√© Databricks.
- Surveillez l'utilisation via les m√©triques Prometheus fournies (`requests_total`, `latency_seconds`, `errors_total`).

---

## üçÉ MongoDB Atlas & Self-hosted

### 1. Connexion

- Utilisez une URI Atlas standard (`mongodb+srv://user:pass@cluster.mongodb.net/db`).
- Ou d√©finissez `MONGODB_URI` dans l'environnement ; sinon fournissez `host`, `port`, `username`, `password`.

```python
import os

config = ConnectionConfig(
    connection_type='mongodb',
    connection_uri=os.environ.get('MONGODB_URI'),
    database='analytics'
)
connector = MongoDBConnector(config)
```

### 2. Astuces de performance

- Limitez `max_rows` pour contr√¥ler le volume de documents rapatri√©s.
- Les champs `_id` sont convertis en cha√Ænes pour faciliter la s√©rialisation JSON.

---

## üìã Google Sheets

### 1. Cr√©er un compte de service Google Cloud

1. Allez sur [Google Cloud Console](https://console.cloud.google.com/)
2. Cr√©ez un nouveau projet ou s√©lectionnez un projet existant
3. Activez l'API Google Sheets :
   - Menu ‚Üí APIs & Services ‚Üí Library
   - Recherchez "Google Sheets API"
   - Cliquez sur "Enable"

### 2. Cr√©er les credentials

1. Menu ‚Üí APIs & Services ‚Üí Credentials
2. Cliquez sur "Create Credentials" ‚Üí "Service account"
3. Remplissez les d√©tails :
   - Service account name: `automl-sheets-access`
   - Service account ID: (auto-g√©n√©r√©)
   - Description: "AutoML Platform Google Sheets access"
4. Cliquez sur "Create and Continue"
5. R√¥le : "Editor" ou "Viewer" selon vos besoins
6. Cliquez sur "Done"

### 3. T√©l√©charger la cl√© JSON

1. Dans la liste des service accounts, cliquez sur celui cr√©√©
2. Onglet "Keys" ‚Üí "Add Key" ‚Üí "Create new key"
3. Choisissez "JSON" et t√©l√©chargez le fichier
4. Sauvegardez ce fichier en s√©curit√©

### 4. Configuration dans AutoML Platform

**Option A : Fichier JSON**
```python
config = ConnectionConfig(
    connection_type='googlesheets',
    spreadsheet_id='your-sheet-id',
    credentials_path='/path/to/service-account-key.json'
)
```

**Option B : Variable d'environnement**
```bash
# Copier tout le contenu du fichier JSON
export GOOGLE_SHEETS_CREDENTIALS='{"type": "service_account", "project_id": "...", ...}'

# Ou utiliser le chemin du fichier
export GOOGLE_APPLICATION_CREDENTIALS="/path/to/service-account-key.json"
```

**Option C : Dans le dashboard web**
- Uploader le fichier JSON via l'interface
- Ou coller le contenu JSON dans le champ d√©di√©

### 5. Partager le Google Sheet

**IMPORTANT** : Partagez votre Google Sheet avec l'email du service account :
1. Ouvrez votre Google Sheet
2. Cliquez sur "Share"
3. Ajoutez l'email du service account (trouv√© dans le fichier JSON sous `client_email`)
4. Donnez les permissions appropri√©es (Editor ou Viewer)

## ü§ù HubSpot

### 1. Obtenir une cl√© API priv√©e

1. Connectez-vous √† votre compte [HubSpot](https://app.hubspot.com)
2. Cliquez sur Settings (ic√¥ne engrenage)
3. Dans le menu lat√©ral : Integrations ‚Üí Private Apps
4. Cliquez sur "Create a private app"
5. Nommez votre app : "AutoML Platform Integration"
6. Dans l'onglet "Scopes", s√©lectionnez :
   - `crm.objects.contacts.read`
   - `crm.objects.contacts.write`
   - `crm.objects.companies.read`
   - `crm.objects.companies.write`
   - `crm.objects.deals.read`
   - `crm.objects.deals.write`
7. Cliquez sur "Create app"
8. Copiez le "Access token"

### 2. Configuration

```bash
# Variable d'environnement
export HUBSPOT_API_KEY="pat-na1-xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx"
```

```python
# Dans le code
config = ConnectionConfig(
    connection_type='hubspot',
    crm_type='hubspot',
    api_key='your-access-token'
)
```

## üíº Salesforce

### 1. Cr√©er une Connected App

1. Login to Salesforce ‚Üí Setup
2. Quick Find ‚Üí "App Manager"
3. New Connected App
4. Remplir :
   - Connected App Name: "AutoML Platform"
   - API Name: "AutoML_Platform"
   - Contact Email: votre email
5. Enable OAuth Settings
6. Callback URL: `http://localhost:8000/callback`
7. Selected OAuth Scopes:
   - Access and manage your data (api)
   - Access your basic information (id, profile, email)
   - Perform requests on your behalf at any time (refresh_token, offline_access)
8. Save

### 2. Obtenir les tokens

```python
import requests

# Obtenir le token
response = requests.post(
    'https://login.salesforce.com/services/oauth2/token',
    data={
        'grant_type': 'password',
        'client_id': 'your-consumer-key',
        'client_secret': 'your-consumer-secret',
        'username': 'your-salesforce-username',
        'password': 'your-salesforce-password' + 'your-security-token'
    }
)
token = response.json()['access_token']
instance_url = response.json()['instance_url']
```

### 3. Configuration

```bash
export SALESFORCE_API_KEY="your-access-token"
export SALESFORCE_INSTANCE_URL="https://your-instance.salesforce.com"
```

## üîß Pipedrive

### 1. Obtenir la cl√© API

1. Connectez-vous √† [Pipedrive](https://app.pipedrive.com)
2. Cliquez sur votre profil (en haut √† droite)
3. Personal preferences ‚Üí API
4. Copiez votre "Personal API token"

### 2. Configuration

```bash
export PIPEDRIVE_API_KEY="your-api-token"
```

```python
config = ConnectionConfig(
    connection_type='pipedrive',
    crm_type='pipedrive',
    api_key='your-api-token'
)
```

## üìä Excel

Aucune configuration n√©cessaire ! Uploadez simplement votre fichier.

### Options avanc√©es

```python
# Lire plusieurs feuilles
config = ConnectionConfig(
    connection_type='excel',
    file_path='data.xlsx'
)
connector = ExcelConnector(config)

# Lister les feuilles disponibles
sheets = connector.list_tables()
print(f"Feuilles disponibles: {sheets}")

# Lire une feuille sp√©cifique
df = connector.read_excel(sheet_name='Sales2024')

# Lire avec options
df = connector.read_excel(
    sheet_name='Data',
    skiprows=2,  # Ignorer les 2 premi√®res lignes
    usecols='A:E'  # Colonnes A √† E uniquement
)
```

## üîê S√©curit√© et Bonnes Pratiques

### 1. Ne jamais committer les credentials

Cr√©ez un fichier `.env` (ajout√© √† `.gitignore`) :
```bash
# .env
GOOGLE_SHEETS_CREDENTIALS='{"type": "service_account", ...}'
HUBSPOT_API_KEY="pat-na1-xxxxxxxx"
SALESFORCE_API_KEY="00D..."
PIPEDRIVE_API_KEY="abc123..."
```

Chargez avec python-dotenv :
```python
from dotenv import load_dotenv
load_dotenv()
```

### 2. Utiliser un gestionnaire de secrets

Pour la production, utilisez :
- AWS Secrets Manager
- Google Secret Manager
- Azure Key Vault
- HashiCorp Vault

### 3. Rotation des cl√©s

- Renouvelez les cl√©s API r√©guli√®rement
- Surveillez les logs d'acc√®s
- R√©voquez les cl√©s non utilis√©es

### 4. Permissions minimales

- Donnez uniquement les permissions n√©cessaires
- Utilisez des comptes de service d√©di√©s
- S√©parez les acc√®s lecture/√©criture

### 5. Throttling & retries centralis√©s

- Configurez `requests_per_minute` pour chaque connecteur critique afin d'√©viter les d√©passements de quotas.
- Ajustez `max_retries`, `retry_backoff_seconds` et `retry_backoff_factor` pour r√©pondre aux SLAs internes.
- Les m√©triques Prometheus (`ml_connectors_requests_total`, `ml_connectors_latency_seconds`, `ml_connectors_errors_total`) facilitent l'audit.

## üß™ Test des Connecteurs

### Script de test complet

```python
"""Test de tous les connecteurs"""
import os
from automl_platform.api.connectors import (
    ConnectionConfig,
    ExcelConnector,
    GoogleSheetsConnector,
    CRMConnector,
    ConnectorFactory
)

def test_excel():
    """Test Excel connector"""
    print("Testing Excel Connector...")
    config = ConnectionConfig(
        connection_type='excel',
        file_path='test_data.xlsx'
    )
    connector = ExcelConnector(config)
    
    # Lire
    df = connector.read_excel()
    print(f"‚úì Read {len(df)} rows from Excel")
    
    # √âcrire
    output_path = connector.write_excel(df, path='output.xlsx')
    print(f"‚úì Wrote to {output_path}")

def test_google_sheets():
    """Test Google Sheets connector"""
    print("Testing Google Sheets Connector...")
    
    if not os.getenv('GOOGLE_SHEETS_CREDENTIALS'):
        print("‚ö† Skipping: No Google Sheets credentials")
        return
    
    config = ConnectionConfig(
        connection_type='googlesheets',
        spreadsheet_id='your-test-sheet-id'
    )
    connector = GoogleSheetsConnector(config)
    connector.connect()
    
    # Lister les feuilles
    sheets = connector.list_tables()
    print(f"‚úì Found sheets: {sheets}")
    
    # Lire
    df = connector.read_google_sheet()
    print(f"‚úì Read {len(df)} rows from Google Sheets")

def test_hubspot():
    """Test HubSpot connector"""
    print("Testing HubSpot Connector...")
    
    if not os.getenv('HUBSPOT_API_KEY'):
        print("‚ö† Skipping: No HubSpot API key")
        return
    
    config = ConnectionConfig(
        connection_type='hubspot',
        crm_type='hubspot'
    )
    connector = CRMConnector(config)
    connector.connect()
    
    # Lister les entit√©s
    entities = connector.list_tables()
    print(f"‚úì Available entities: {entities}")
    
    # Lire les contacts
    df = connector.fetch_crm_data('contacts', limit=10)
    print(f"‚úì Fetched {len(df)} contacts from HubSpot")

if __name__ == "__main__":
    test_excel()
    test_google_sheets()
    test_hubspot()
    print("\n‚úÖ All tests completed!")
```

## üö® Troubleshooting

### Google Sheets

**Erreur : "Google Sheets API has not been enabled"**
- Solution : Activez l'API dans Google Cloud Console

**Erreur : "Permission denied"**
- Solution : Partagez le Sheet avec l'email du service account

**Erreur : "Invalid credentials"**
- Solution : V√©rifiez le format JSON et les escape characters

### HubSpot

**Erreur : "Invalid authentication"**
- Solution : V√©rifiez que le token commence par "pat-"

**Erreur : "Rate limit exceeded"**
- Solution : Impl√©mentez un retry avec d√©lai exponentiel

### Salesforce

**Erreur : "Invalid grant"**
- Solution : V√©rifiez le security token et l'IP whitelist

**Erreur : "Session expired"**
- Solution : Impl√©mentez la logique de refresh token

## üìö Ressources

- [Google Sheets API Documentation](https://developers.google.com/sheets/api)
- [HubSpot API Documentation](https://developers.hubspot.com/docs/api)
- [Salesforce API Documentation](https://developer.salesforce.com/docs/apis)
- [Pipedrive API Documentation](https://developers.pipedrive.com/docs/api)

## üí° Exemples d'Usage Avanc√©s

### Pipeline complet Excel ‚Üí ML ‚Üí CRM

```python
from automl_platform.api.connectors import *
from automl_platform.orchestrator import AutoMLOrchestrator

# 1. Lire depuis Excel
excel_config = ConnectionConfig(connection_type='excel', file_path='customers.xlsx')
excel = ExcelConnector(excel_config)
df = excel.read_excel()

# 2. Entra√Æner le mod√®le
orchestrator = AutoMLOrchestrator()
X = df.drop('churned', axis=1)
y = df['churned']
orchestrator.fit(X, y)

# 3. Pr√©dire sur nouvelles donn√©es Google Sheets
sheets_config = ConnectionConfig(
    connection_type='googlesheets',
    spreadsheet_id='new-customers-sheet-id'
)
sheets = GoogleSheetsConnector(sheets_config)
sheets.connect()
new_customers = sheets.read_google_sheet()

predictions = orchestrator.predict_proba(new_customers)

# 4. Envoyer les r√©sultats vers HubSpot
hubspot_config = ConnectionConfig(
    connection_type='hubspot',
    crm_type='hubspot'
)
crm = CRMConnector(hubspot_config)
crm.connect()

results_df = new_customers.copy()
results_df['churn_risk'] = predictions[:, 1]
results_df['segment'] = pd.cut(predictions[:, 1], 
                               bins=[0, 0.3, 0.7, 1.0],
                               labels=['Low', 'Medium', 'High'])

crm.write_crm_data(results_df, destination='contacts', update_existing=True)
print("‚úÖ Pipeline completed successfully!")
```
