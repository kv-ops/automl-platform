# AutoML Platform - Guide de D√©ploiement SaaS

## Table des mati√®res

1. [Vue d'ensemble](#vue-densemble)
2. [Pr√©requis](#pr√©requis)
3. [Installation rapide](#installation-rapide)
4. [Configuration d√©taill√©e](#configuration-d√©taill√©e)
5. [D√©ploiement en production](#d√©ploiement-en-production)
6. [Configuration SSO](#configuration-sso)
7. [Stockage et persistance](#stockage-et-persistance)
8. [Monitoring et supervision](#monitoring-et-supervision)
9. [Sauvegarde et restauration](#sauvegarde-et-restauration)
10. [D√©pannage](#d√©pannage)

## Vue d'ensemble

L'AutoML Platform en mode SaaS est une solution compl√®te pr√™te √† d√©ployer qui comprend :

- **API Backend** : FastAPI avec authentification JWT et SSO
- **Interface Web** : Application Streamlit no-code pour les utilisateurs non techniques
- **Workers** : Traitement distribu√© avec Celery pour l'entra√Ænement des mod√®les
- **Stockage** : MinIO (S3-compatible) pour les datasets et mod√®les
- **Base de donn√©es** : PostgreSQL pour les m√©tadonn√©es
- **Cache** : Redis pour les sessions et la communication inter-services
- **SSO** : Keycloak pour l'authentification d'entreprise
- **Monitoring** : Prometheus + Grafana pour la supervision

## Pr√©requis

### Configuration syst√®me minimale

- **CPU** : 4 c≈ìurs minimum (8 recommand√©s)
- **RAM** : 8 GB minimum (16 GB recommand√©s)
- **Stockage** : 50 GB d'espace libre
- **OS** : Linux (Ubuntu 20.04+, CentOS 8+) ou macOS
- **R√©seau** : Ports 80, 443, 8000, 8501 disponibles

### Logiciels requis

```bash
# Docker (version 20.10+)
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh

# Docker Compose (version 2.0+)
sudo curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose

# Git
sudo apt-get update && sudo apt-get install -y git

# Make et outils de build (optionnel)
sudo apt-get install -y make build-essential
```

### Support GPU (optionnel)

Pour le support GPU avec NVIDIA :

```bash
# NVIDIA Container Toolkit
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list

sudo apt-get update && sudo apt-get install -y nvidia-container-toolkit
sudo systemctl restart docker
```

## Installation rapide

### 1. Cloner le d√©p√¥t

```bash
git clone https://github.com/your-org/automl-platform.git
cd automl-platform
```

### 2. D√©ploiement automatique

Utilisez le script de d√©ploiement pour une installation automatis√©e :

```bash
# D√©ploiement production standard
./scripts/deploy_saas.sh --env prod

# D√©ploiement avec monitoring
./scripts/deploy_saas.sh --env prod --monitoring

# D√©ploiement avec GPU
./scripts/deploy_saas.sh --env prod --gpu

# D√©ploiement complet avec toutes les options
./scripts/deploy_saas.sh --env prod --monitoring --gpu --scale 4
```

### 3. Acc√®s √† la plateforme

Une fois le d√©ploiement termin√©, acc√©dez √† :

- **Interface Web** : http://localhost:8501
- **API** : http://localhost:8000
- **Documentation API** : http://localhost:8000/docs
- **MLflow** : http://localhost:5000
- **Keycloak Admin** : http://localhost:8080/admin

## Configuration d√©taill√©e

### Variables d'environnement

Cr√©ez un fichier `.env` √† la racine du projet :

```env
# =============================================================================
# Configuration principale
# =============================================================================

# Mode de d√©ploiement
ENVIRONMENT=production
AUTOML_MODE=saas
AUTOML_EXPERT_MODE=false  # false pour les utilisateurs non techniques

# =============================================================================
# Base de donn√©es
# =============================================================================

POSTGRES_USER=automl
POSTGRES_PASSWORD=your-secure-password-here
POSTGRES_DB=automl
POSTGRES_HOST=postgres
POSTGRES_PORT=5432

# =============================================================================
# Redis
# =============================================================================

REDIS_PASSWORD=your-redis-password-here
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_URL=redis://:${REDIS_PASSWORD}@${REDIS_HOST}:${REDIS_PORT}/0  # Utilis√© par le middleware d'authentification

# =============================================================================
# Stockage MinIO (S3-compatible)
# =============================================================================

MINIO_ACCESS_KEY=your-minio-access-key
MINIO_SECRET_KEY=your-minio-secret-key
MINIO_ENDPOINT=minio:9000
MINIO_SECURE=false

# Buckets
S3_BUCKET_MODELS=models
S3_BUCKET_DATASETS=datasets
S3_BUCKET_ARTIFACTS=artifacts
S3_BUCKET_REPORTS=reports

# =============================================================================
# API Configuration
# =============================================================================

API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=4
JWT_SECRET_KEY=your-very-long-secret-key-change-this-in-production
JWT_ALGORITHM=HS256
JWT_EXPIRATION_HOURS=24

# CORS
CORS_ORIGINS=http://localhost:3000,http://localhost:8501,https://yourdomain.com

# Rate limiting
RATE_LIMIT_ENABLED=true
DEFAULT_RATE_LIMIT=100  # requests per minute

# =============================================================================
# Interface Web (UI)
# =============================================================================

UI_PORT=8501
UI_FRAMEWORK=streamlit
UI_TITLE=AutoML Platform
UI_THEME=light
MAX_UPLOAD_SIZE=1000  # MB

# URLs publiques
PUBLIC_API_URL=https://api.yourdomain.com
PUBLIC_UI_URL=https://app.yourdomain.com

# Fonctionnalit√©s
ENABLE_CHAT_ASSISTANT=true
ENABLE_AUTO_ML=true
ENABLE_EXPERT_MODE=false
ENABLE_COLLABORATION=true
DEFAULT_LANGUAGE=fr

# =============================================================================
# SSO - Keycloak
# =============================================================================

SSO_ENABLED=true
KEYCLOAK_ENABLED=true
KEYCLOAK_URL=http://keycloak:8080
KEYCLOAK_REALM=automl
KEYCLOAK_CLIENT_ID=automl-platform
KEYCLOAK_CLIENT_SECRET=your-keycloak-secret
KEYCLOAK_ADMIN=admin
KEYCLOAK_ADMIN_PASSWORD=your-admin-password

# Alternative: Auth0
AUTH0_ENABLED=false
AUTH0_DOMAIN=your-tenant.auth0.com
AUTH0_CLIENT_ID=your-client-id
AUTH0_CLIENT_SECRET=your-client-secret

# Alternative: Okta
OKTA_ENABLED=false
OKTA_DOMAIN=your-org.okta.com
OKTA_CLIENT_ID=your-client-id
OKTA_CLIENT_SECRET=your-client-secret

# =============================================================================
# MLflow
# =============================================================================

MLFLOW_TRACKING_URI=http://mlflow:5000
MLFLOW_USER=mlflow
MLFLOW_PASSWORD=mlflow-password

# =============================================================================
# Workers (Celery)
# =============================================================================

CELERY_BROKER_URL=redis://:${REDIS_PASSWORD}@redis:6379/0
CELERY_RESULT_BACKEND=redis://:${REDIS_PASSWORD}@redis:6379/0
CPU_WORKER_REPLICAS=2
CPU_WORKER_CONCURRENCY=4
WORKER_MAX_MEMORY_GB=8

# GPU Workers (optionnel)
GPU_WORKER_REPLICAS=0
CUDA_VISIBLE_DEVICES=0

# =============================================================================
# LLM APIs (optionnel)
# =============================================================================

OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
ENABLE_AI_ASSISTANT=true

# =============================================================================
# Multi-tenant
# =============================================================================

MULTI_TENANT_ENABLED=true
DEFAULT_TENANT_PLAN=trial
TRIAL_DURATION_DAYS=14

# Quotas par d√©faut
DEFAULT_MAX_WORKERS=2
DEFAULT_MAX_CONCURRENT_JOBS=2
DEFAULT_STORAGE_QUOTA_GB=10
DEFAULT_MONTHLY_COMPUTE_MINUTES=1000

# =============================================================================
# Monitoring
# =============================================================================

PROMETHEUS_PORT=9090
GRAFANA_PORT=3000
GRAFANA_USER=admin
GRAFANA_PASSWORD=grafana-password

# =============================================================================
# Backup
# =============================================================================

BACKUP_ENABLED=true
BACKUP_SCHEDULE="0 2 * * *"  # 2h du matin chaque jour
BACKUP_RETENTION_DAYS=30
BACKUP_S3_BUCKET=backups
```

### G√©n√©ration s√©curis√©e des secrets

Les services refuseront d√©sormais de d√©marrer si des secrets critiques sont
absents ou contiennent les valeurs d'exemple historiques (`minioadmin`,
`change-this-secret-key`, etc.). G√©n√©rez syst√©matiquement vos secrets via une
source cryptographiquement s√©curis√©e‚ÄØ:

```bash
# Cl√© secr√®te de plateforme (AUTOML_SECRET_KEY)
python - <<'PY'
import secrets
print(secrets.token_urlsafe(64))
PY

# Identifiants MinIO compatibles avec la validation
export MINIO_ACCESS_KEY="$(openssl rand -hex 16)"
export MINIO_SECRET_KEY="$(openssl rand -base64 32)"

# Secret JWT robuste
openssl rand -base64 48
```

Le script `scripts/deploy_saas.sh` applique automatiquement ces commandes via
`openssl rand`. Pour les environnements g√©r√©s (Vault, AWS Secrets Manager,
Kubernetes Secrets, etc.), stockez ces valeurs hors du d√©p√¥t Git et r√©f√©rencez
les uniquement via des variables d'environnement.

### Migration depuis les anciennes valeurs par d√©faut

Lors d'une mise √† niveau, la plateforme √©choue volontairement au d√©marrage si
les anciens identifiants `minioadmin` ou les secrets JWT de d√©monstration sont
toujours pr√©sents. Proc√©dez comme suit pour migrer en conservant vos donn√©es‚ÄØ:

1. **G√©n√©rez les nouveaux secrets** (voir ci-dessus) et enregistrez-les dans
   votre gestionnaire de secrets.
2. **Mettez √† jour** le `.env`, les fichiers `docker-compose.override.yml` ou
   les manifests Kubernetes avec `AUTOML_SECRET_KEY`, `MINIO_ACCESS_KEY` et
   `MINIO_SECRET_KEY` fraichement g√©n√©r√©s.
3. **Rotation MinIO** : si vous utilisiez l'utilisateur racine `minioadmin`,
   cr√©ez un nouvel utilisateur avec les nouveaux identifiants, migrez les
   politiques et d√©sactivez l'ancien compte avant red√©marrage. D√©finissez au
   pr√©alable la valeur de l'ancien secret (`export MINIO_OLD_SECRET="<mot de passe actuel>"`) puis ex√©cutez :

   ```bash
   docker compose exec minio sh -c '
     mc alias set local http://localhost:9000 minioadmin ${MINIO_OLD_SECRET};
     mc admin user add local "$MINIO_ACCESS_KEY" "$MINIO_SECRET_KEY";
     mc admin policy attach local readwrite --user "$MINIO_ACCESS_KEY";
     mc admin user disable local minioadmin
   '
   ```

   Les buckets existants restent accessibles ; seule l'identit√© utilis√©e par la
   plateforme change.
4. **Red√©marrez** la stack (`docker compose up -d --force-recreate`) et
   v√©rifiez les journaux pour confirmer l'utilisation des nouveaux secrets.

> üí° **Astuce s√©curit√©** : d'autres secrets (PostgreSQL, Redis, Grafana, Flower,
> etc.) ne disposent pas encore de validation centralis√©e. Appliquez le m√™me
> processus de g√©n√©ration et de rotation pour maintenir un niveau de s√©curit√©
> homog√®ne.

### Configuration Docker Compose

Le fichier `docker-compose.yml` est d√©j√† configur√©. Pour personnaliser :

```yaml
# Modifier les limites de ressources
services:
  worker-cpu:
    deploy:
      resources:
        limits:
          cpus: "8"      # Augmenter les CPU
          memory: 16G    # Augmenter la RAM
```

## D√©ploiement en production

### 1. Pr√©paration du serveur

```bash
# Mise √† jour syst√®me
sudo apt-get update && sudo apt-get upgrade -y

# Configuration firewall
sudo ufw allow 22/tcp    # SSH
sudo ufw allow 80/tcp    # HTTP
sudo ufw allow 443/tcp   # HTTPS
sudo ufw allow 8000/tcp  # API
sudo ufw allow 8501/tcp  # UI
sudo ufw enable

# Configuration swap (recommand√©)
sudo fallocate -l 8G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile
echo '/swapfile none swap sw 0 0' | sudo tee -a /etc/fstab
```

### 2. Configuration HTTPS avec Let's Encrypt

```bash
# Installation Certbot
sudo apt-get install -y certbot

# G√©n√©ration certificat
sudo certbot certonly --standalone -d yourdomain.com -d api.yourdomain.com

# Configuration Nginx (optionnel)
docker-compose --profile production up -d nginx
```

### 3. D√©ploiement avec Docker Swarm (haute disponibilit√©)

```bash
# Initialiser Swarm
docker swarm init --advertise-addr <MANAGER-IP>

# D√©ployer la stack
docker stack deploy -c docker-compose.yml automl

# Scaler les services
docker service scale automl_worker-cpu=5
```

### 4. Configuration DNS

Configurez vos enregistrements DNS :

```
A    @              -> YOUR_SERVER_IP
A    api            -> YOUR_SERVER_IP
A    app            -> YOUR_SERVER_IP
A    mlflow         -> YOUR_SERVER_IP
A    keycloak       -> YOUR_SERVER_IP
```

## Configuration SSO

### Keycloak

1. **Acc√©der √† la console admin** : http://localhost:8080/admin

2. **Cr√©er un realm** :
   - Nom : `automl`
   - Display name : `AutoML Platform`

3. **Configurer le client** :
   ```json
   {
     "clientId": "automl-platform",
     "rootUrl": "http://localhost:8501",
     "redirectUris": ["http://localhost:8501/*"],
     "webOrigins": ["http://localhost:8501"],
     "publicClient": false,
     "protocol": "openid-connect",
     "standardFlowEnabled": true,
     "implicitFlowEnabled": false,
     "directAccessGrantsEnabled": true
   }
   ```

4. **Cr√©er des r√¥les** :
   - `admin` : Acc√®s complet
   - `data_scientist` : Cr√©ation et gestion de projets
   - `viewer` : Lecture seule
   - `trial` : Acc√®s limit√©

5. **Mapper les attributs** :
   - email ‚Üí email
   - given_name ‚Üí firstName
   - family_name ‚Üí lastName
   - groups ‚Üí groups

### Auth0 (Alternative)

1. **Cr√©er une application** :
   - Type : Regular Web Application
   - Allowed Callback URLs : `http://localhost:8501/callback`
   - Allowed Logout URLs : `http://localhost:8501`

2. **Configurer les r√®gles** :
   ```javascript
   function addAppMetadata(user, context, callback) {
     user.app_metadata = user.app_metadata || {};
     user.app_metadata.roles = user.app_metadata.roles || [];
     user.app_metadata.plan = user.app_metadata.plan || 'trial';
     
     context.idToken['https://automl/roles'] = user.app_metadata.roles;
     context.idToken['https://automl/plan'] = user.app_metadata.plan;
     
     callback(null, user, context);
   }
   ```

### Azure AD (Alternative)

1. **Enregistrer l'application** :
   - Redirect URI : `http://localhost:8501/callback`
   - Supported account types : Multitenant

2. **Configurer les permissions API** :
   - Microsoft Graph : User.Read
   - Custom scopes : automl.read, automl.write

## Stockage et persistance

### Configuration MinIO

1. **G√©n√©rer des identifiants s√©curis√©s** :
   ```bash
   export MINIO_ACCESS_KEY="$(openssl rand -hex 16)"
   export MINIO_SECRET_KEY="$(openssl rand -base64 32)"
   ```
   Conservez ces valeurs dans votre gestionnaire de secrets (Vault, AWS Secrets Manager, etc.).

2. **Acc√©der √† la console** : http://localhost:9001 (authentification avec les secrets g√©n√©r√©s)

3. **Cr√©er les buckets** :
   ```bash
   # Via MC CLI
   docker exec -it automl_minio mc alias set local http://localhost:9000 "$MINIO_ACCESS_KEY" "$MINIO_SECRET_KEY"
   docker exec -it automl_minio mc mb local/models
   docker exec -it automl_minio mc mb local/datasets
   docker exec -it automl_minio mc mb local/artifacts
   ```

4. **Configurer les politiques** :
   ```json
   {
     "Version": "2012-10-17",
     "Statement": [
       {
         "Effect": "Allow",
         "Principal": {"AWS": ["*"]},
         "Action": ["s3:GetObject"],
         "Resource": ["arn:aws:s3:::reports/*"]
       }
     ]
   }
   ```

> ‚ÑπÔ∏è **Rotation** : planifiez la rotation des identifiants MinIO via votre gestionnaire de secrets.
> Les services refuseront de d√©marrer tant que les nouvelles valeurs ne sont pas propag√©es.

### Volumes Docker

Les donn√©es sont persist√©es dans des volumes Docker :

- `postgres_data` : Base de donn√©es
- `redis_data` : Cache et sessions
- `minio_data` : Fichiers et mod√®les
- `shared_models` : Mod√®les partag√©s entre services

### D√©sactiver la persistance

Pour des environnements √©ph√©m√®res (CI, notebooks temporaires, d√©monstrations),
il est possible de d√©sactiver compl√®tement la persistance des artefacts en
configurant `storage.backend: none`. Dans ce mode, la plateforme instancie un
``StorageManager`` sp√©cial qui l√®ve imm√©diatement une erreur explicite si une
op√©ration de sauvegarde ou de chargement est invoqu√©e. Cela permet de d√©tecter
rapidement les usages qui supposent une persistance tout en √©vitant de cr√©er
des dossiers temporaires non d√©sir√©s.

### Configuration Google Cloud Storage

L'option `storage.backend: gcs` permet de d√©l√©guer le stockage des mod√®les et des jeux de donn√©es √† Google Cloud Storage. Pour un d√©ploiement s√©curis√© :

1. **Cr√©ation des buckets** : cr√©ez manuellement (ou via IaC) les buckets `models`, `datasets` et `artifacts` dans votre projet GCP. Assignez-leur une strat√©gie de r√©tention adapt√©e √† vos contraintes de conformit√©.
2. **Authentification** :
   - En d√©veloppement, utilisez un compte de service d√©di√© (r√¥le minimal `Storage Object Admin`) et exposez son chemin via la cl√© `storage.credentials_path` ou la variable d'environnement `GOOGLE_APPLICATION_CREDENTIALS`.
   - En production sur GKE, privil√©giez **Workload Identity** afin d'√©viter la distribution de fichiers de cl√©s.
3. **S√©curit√© des secrets** : ne validez jamais les fichiers de cr√©dential dans Git. Stockez-les dans un coffre-fort (Secret Manager, Vault‚Ä¶) et montez-les au runtime.
4. **Validation** : ex√©cutez `pytest tests/test_storage.py::TestStorageManager::test_storage_manager_gcs_backend` pour v√©rifier que la configuration GCS est fonctionnelle.

> üí° Lorsque `storage.credentials_path` est d√©fini, la validation de configuration s'assure d√©sormais que le fichier existe r√©ellement afin d'√©viter les d√©ploiements incomplets.

## Monitoring et supervision

### Prometheus

Configuration dans `monitoring/prometheus.yml` :

```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'api'
    static_configs:
      - targets: ['api:8000']
    
  - job_name: 'mlflow'
    static_configs:
      - targets: ['mlflow:5000']
    
  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']
    
  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres-exporter:9187']
```

### Grafana

1. **Acc√©der** : http://localhost:3000

2. **Importer les dashboards** :
   - AutoML Overview (ID: 15001)
   - ML Training Metrics (ID: 15002)
   - API Performance (ID: 15003)

3. **Configurer les alertes** :
   ```yaml
   groups:
     - name: automl_alerts
       rules:
         - alert: HighAPILatency
           expr: http_request_duration_seconds > 1
           for: 5m
           annotations:
             summary: "API latency is high"
   ```

### Logs centralis√©s

Pour ELK Stack (optionnel) :

```yaml
# Ajouter dans docker-compose.yml
elasticsearch:
  image: elasticsearch:8.11.0
  environment:
    - discovery.type=single-node
    - ES_JAVA_OPTS=-Xms512m -Xmx512m

kibana:
  image: kibana:8.11.0
  depends_on:
    - elasticsearch
  ports:
    - "5601:5601"
```

## Sauvegarde et restauration

### Sauvegarde automatique

Le script de backup est programm√© via Celery Beat :

```python
# automl_platform/tasks/backup.py
from celery import shared_task
import subprocess

@shared_task
def backup_database():
    """Sauvegarde quotidienne de la base de donn√©es"""
    subprocess.run([
        "pg_dump",
        "-h", "postgres",
        "-U", "automl",
        "-d", "automl",
        "-f", f"/backups/db_{datetime.now()}.sql"
    ])
```

### Sauvegarde manuelle

```bash
# Sauvegarde compl√®te
./scripts/deploy_saas.sh --backup

# Sauvegarde sp√©cifique
docker exec automl_postgres pg_dump -U automl automl > backup.sql
docker exec automl_redis redis-cli --auth $REDIS_PASSWORD BGSAVE
```

### Restauration

```bash
# Restauration depuis une sauvegarde
./scripts/deploy_saas.sh --restore backup_20240101_120000.tar.gz

# Restauration manuelle de la base
docker exec -i automl_postgres psql -U automl automl < backup.sql
```

## D√©pannage

### Probl√®mes courants

#### 1. Services ne d√©marrent pas

```bash
# V√©rifier les logs
docker-compose logs -f api
docker-compose logs -f ui

# V√©rifier l'√©tat des conteneurs
docker-compose ps

# Red√©marrer les services
docker-compose restart api ui
```

#### 2. Erreurs de connexion √† la base de donn√©es

```bash
# V√©rifier PostgreSQL
docker exec -it automl_postgres psql -U automl -d automl -c "\l"

# Recr√©er la base si n√©cessaire
docker-compose down -v
docker-compose up -d postgres
docker-compose up -d
```

#### 3. Probl√®mes SSO/Keycloak

```bash
# R√©initialiser Keycloak
docker-compose stop keycloak
docker volume rm automl_keycloak_data
docker-compose up -d keycloak

# V√©rifier la configuration
curl http://localhost:8080/realms/automl/.well-known/openid-configuration
```

#### 4. Espace disque insuffisant

```bash
# Nettoyer Docker
docker system prune -a -f
docker volume prune -f

# V√©rifier l'utilisation
docker system df
df -h
```

### Logs et debugging

```bash
# Tous les logs
docker-compose logs -f

# Logs sp√©cifiques
docker-compose logs -f api --tail=100
docker-compose logs -f worker-cpu --tail=100

# Mode debug
export LOG_LEVEL=debug
docker-compose up
```

### Support

Pour obtenir de l'aide :

1. Consultez la [documentation compl√®te](https://docs.automl-platform.com)
2. Ouvrez une issue sur [GitHub](https://github.com/your-org/automl-platform/issues)
3. Contactez le support : support@automl-platform.com

## Annexes

### Architecture compl√®te

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         Nginx (Reverse Proxy)                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ                                ‚îÇ
             ‚ñº                                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    UI (Streamlit)   ‚îÇ          ‚îÇ   API (FastAPI)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ                                 ‚îÇ
           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
                        ‚ñº
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ      Message Broker          ‚îÇ
         ‚îÇ         (Redis)              ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚ñº                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  CPU Workers  ‚îÇ      ‚îÇ  GPU Workers  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                       ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ         Storage Layer             ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îÇ  PostgreSQL ‚îÇ MinIO ‚îÇ MLflow      ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Checklist de production

- [ ] Variables d'environnement s√©curis√©es
- [ ] HTTPS configur√©
- [ ] Sauvegardes automatiques activ√©es
- [ ] Monitoring en place
- [ ] Logs centralis√©s
- [ ] SSO configur√© et test√©
- [ ] Firewall configur√©
- [ ] Limites de ressources d√©finies
- [ ] Health checks configur√©s
- [ ] Documentation √† jour
- [ ] Plan de reprise d'activit√© test√©
